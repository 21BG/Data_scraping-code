{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://howpcrules.com/step-by-step-guide-on-scraping-data-from-a-website-and-saving-it-to-a-database/\n",
    "\n",
    "import requests\n",
    "import MySQLdb\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL connection data to connect and save the data in\n",
    "HOST = \"localhost\"\n",
    "USERNAME = \"scraping_user\"\n",
    "PASSWORD = \"\"\n",
    "DATABASE = \"scraping_sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape the same page twice. If you are planning to scrape multiple pages with a similiar design, use \"i\" to generate different urls.\n",
    "for i in range(0, 2):\n",
    "    #URL to be scraped\n",
    "    url_to_scrape = 'https://howpcrules.com/sample-page-for-web-scraping/'\n",
    "    #Load html's plain data into a variable\n",
    "    #plain_html_text = requests.get(url_to_scrape)\n",
    "    plain_html_text = requests.get(list_url[i])\n",
    "    #parse the data\n",
    "    soup = BeautifulSoup(plain_html_text.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #print the whole html data to screen\n",
    "    #print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Get the name of the class\n",
    "    name_of_class = soup.h3.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Get all data associated with this class\n",
    "    basic_data_table = soup.find(\"table\", {\"summary\": \"Basic data for the event\"});\n",
    "    #Get all cells in the base data table\n",
    "    basic_data_cells = basic_data_table.findAll('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #get all the different data from the table's tds\n",
    "    type_of_course = basic_data_cells[0].text.strip()\n",
    "    lecturer = basic_data_cells[1].text.strip()\n",
    "    number = basic_data_cells[2].text.strip()\n",
    "    short_text = basic_data_cells[3].text.strip()\n",
    "    choice_term = basic_data_cells[4].text.strip()\n",
    "    hours_per_week_in_term = basic_data_cells[5].text.strip()\n",
    "    expected_num_of_participants = basic_data_cells[6].text.strip()\n",
    "    maximum_participants = basic_data_cells[7].text.strip()\n",
    "    assignment = basic_data_cells[8].text.strip()\n",
    "    lecture_id = basic_data_cells[9].text.strip()\n",
    "    credit_points = basic_data_cells[10].text.strip()\n",
    "    hyperlink = basic_data_cells[11].text.strip()\n",
    "    language = basic_data_cells[12].text.strip()\n",
    "    #To save data\n",
    "    #Save class's base data to the database\n",
    "# Open database connection\n",
    "db = MySQLdb.connect(HOST, USERNAME, PASSWORD, DATABASE)\n",
    "# prepare a cursor object using cursor() method\n",
    "cursor = db.cursor()\n",
    "# Prepare SQL query to INSERT a record into the database.\n",
    "sql = \"INSERT INTO classes(name_of_class, type_of_course, lecturer, number, short_text, choice_term, hours_per_week_in_term, expected_num_of_participants, maximum_participants, assignment, lecture_id, credit_points, hyperlink, language, created_at) VALUES ('{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', {})\".format(name_of_class, type_of_course, lecturer, number, short_text, choice_term, hours_per_week_in_term, expected_num_of_participants, maximum_participants, assignment, lecture_id, credit_points, hyperlink, language, 'NOW()')\n",
    "try:\n",
    " # Execute the SQL command\n",
    " cursor.execute(sql)\n",
    " # Commit your changes in the database\n",
    " db.commit()\n",
    "except:\n",
    " # Rollback in case there is any error\n",
    " db.rollback()\n",
    " #get the just inserted class id\n",
    "sql = \"SELECT LAST_INSERT_ID()\"\n",
    "try:\n",
    " # Execute the SQL command\n",
    " cursor.execute(sql)\n",
    " # Get the result\n",
    " result = cursor.fetchone()\n",
    " # Set the class id to the just inserted class\n",
    " class_id = result[0]\n",
    "except:\n",
    " # Rollback in case there is any error\n",
    " db.rollback()\n",
    " # disconnect from server\n",
    " db.close()\n",
    " # on error set the class_id to -1\n",
    " class_id = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the tables where the dates are written.\n",
    "dates_tables = soup.find_all(\"table\", {\"summary\": \"Overview of all event dates\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The part with SQL can be found https://howpcrules.com/step-by-step-guide-on-scraping-data-from-a-website-and-saving-it-to-a-database/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
